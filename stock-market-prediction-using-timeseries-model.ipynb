{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from matplotlib import pyplot\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "import pytse_client as tse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_PERCENTAGE = 0.7\n",
    "TESTING_PERCENTAGE = 1 - TRAINING_PERCENTAGE\n",
    "NUMBER_OF_PREVIOUS_DATA_POINTS = 3\n",
    "LENGTH_DATA_SET = 0\n",
    "TRAINING_SET_LENGTH = 0\n",
    "TESTING_SET_LENGTH = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_testing_buckets(raw_data, training_percentage, testing_percentage):\n",
    "    global TRAINING_SET_LENGTH, TESTING_SET_LENGTH\n",
    "    TRAINING_SET_LENGTH = int(LENGTH_DATA_SET * training_percentage)\n",
    "    TESTING_SET_LENGTH = LENGTH_DATA_SET - TRAINING_SET_LENGTH\n",
    "    training_set, testing_set = raw_data[0:TRAINING_SET_LENGTH], raw_data[TRAINING_SET_LENGTH:LENGTH_DATA_SET]\n",
    "    return training_set, testing_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_performance_arima(testing_actual, testing_predict):\n",
    "    counter = 0\n",
    "    for i in range(len(testing_actual)-1):\n",
    "        predict=testing_predict[i+1]- testing_predict[i]\n",
    "        actual = testing_actual[i+1]-testing_actual[i]\n",
    "        if (actual > 0 and predict > 0) or (actual < 0 and predict < 0):\n",
    "            counter+=1\n",
    "    counter = round((counter / (len(testing_actual)-1))*100,2)\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_arima(currency, testing_actual, testing_predict):\n",
    "    actual = pyplot.plot(testing_actual, label=\"Actual data points\", color=\"blue\")\n",
    "    testing = pyplot.plot(testing_predict, label=\"Testing prediction\", color=\"green\")\n",
    "    pyplot.ylabel('currency values for 1 stock')\n",
    "    pyplot.xlabel('number of days')\n",
    "    pyplot.title( currency + ' : actual vs predicted ')\n",
    "    pyplot.legend()\n",
    "    pyplot.show()\n",
    "    pyplot.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_predict_arima(training_set, testing_set):\n",
    "    testing_predict = list()\n",
    "    training_predict = list(training_set)\n",
    "    for testing_set_index in range(TESTING_SET_LENGTH):\n",
    "        arima = ARIMA(training_predict, order=(5, 1, 0))\n",
    "        arima_model = arima.fit(disp=0)\n",
    "        forecasting = arima_model.forecast()[0].tolist()[0]\n",
    "        testing_predict.append(forecasting)\n",
    "        training_predict.append(testing_set[testing_set_index])\n",
    "        # print(\"Predicted = \", testing_predict[-1], \"Expected = \", testing_set[testing_set_index])\n",
    "    print('predicting...')\n",
    "    forcast = arima_model.forecast()[0]\n",
    "    print('The prediction for the next day:', forcast)\n",
    "    if forcast- testing_set[-1] > 0 : print(\"last result = +1\")\n",
    "    else :  print(\"last result = -1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arima_model(currency):\n",
    "    print('\\nARIMA Model')\n",
    "\n",
    "    print('loading the dataset...')\n",
    "    raw_data = load_data_set(currency)\n",
    "\n",
    "    print('splitting training and testing set...')\n",
    "    training_actual_arima, testing_actual_arima = training_testing_buckets(raw_data, TRAINING_PERCENTAGE,\n",
    "                                                                           TESTING_PERCENTAGE)\n",
    "\n",
    "    print('building and training model...')\n",
    "    testing_predict_arima = build_model_predict_arima(training_actual_arima, testing_actual_arima)\n",
    "\n",
    "    print('evaluating performance...')\n",
    "    mse_arima = evaluate_performance_arima(testing_actual_arima, testing_predict_arima)\n",
    "    print('Testing Accuracy: ', mse_arima,\"%\")\n",
    "    print('plotting the graph...')\n",
    "    plot_arima(currency, testing_actual_arima, testing_predict_arima)\n",
    "\n",
    "    return raw_data, testing_predict_arima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    # stock_name = input('Enter stock name:')\n",
    "    stock_name = 'п┤пе'\n",
    "    arima_model(stock_name)  # setting the entry point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
